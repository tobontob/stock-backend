#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from news_analyzer.main import NewsAnalyzer
from news_analyzer.analyze_sentiment import ensemble_sentiment_analysis
from news_analyzer.explain_util import generate_contextual_explanation, generate_multi_perspective_explanation
from news_analyzer.article_crawler import fetch_article_content
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_news_analyzer():
    """NewsAnalyzer í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("=== NewsAnalyzer í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        analyzer = NewsAnalyzer()
        print("âœ… NewsAnalyzer ì´ˆê¸°í™” ì„±ê³µ")
        print(f"  - ì¢…ëª© ìˆ˜: {len(analyzer.stock_list)}")
        print(f"  - ê¸ì • ë‹¨ì–´ ìˆ˜: {len(analyzer.positive_words)}")
        print(f"  - ë¶€ì • ë‹¨ì–´ ìˆ˜: {len(analyzer.negative_words)}")
        print(f"  - ì˜í–¥ ê·œì¹™ ìˆ˜: {len(analyzer.impact_rules)}")
        
        return analyzer
    except Exception as e:
        print(f"âŒ NewsAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

def test_sentiment_analysis():
    """ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("\n=== ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ ===")
    
    test_texts = [
        "ì‚¼ì„±ì „ì ì‹¤ì  í˜¸ì¡°ë¡œ ì£¼ê°€ ìƒìŠ¹ì„¸",
        "LGì „ì ë§¤ì¶œ ê°ì†Œë¡œ ì£¼ê°€ í•˜ë½",
        "SKí•˜ì´ë‹‰ìŠ¤ íˆ¬ì í™•ëŒ€ë¡œ ê¸ì •ì  ì „ë§",
        "í˜„ëŒ€ì°¨ ë¶€ë„ ìœ„ê¸°ë¡œ ì‹œì¥ ìš°ë ¤ê° í™•ì‚°",
        "ì¹´ì¹´ì˜¤ ì‹ ì œí’ˆ ì¶œì‹œë¡œ ê¸°ëŒ€ê° ìƒìŠ¹"
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: {text}")
        try:
            result = ensemble_sentiment_analysis(text)
            print(f"  ê²°ê³¼: {result['label']} (ì‹ ë¢°ë„: {result['score']})")
            print(f"  ê·¼ê±°: {result['reason']}")
        except Exception as e:
            print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")

def test_stock_extraction(analyzer):
    """ì¢…ëª© ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n=== ì¢…ëª© ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ===")
    
    test_texts = [
        "ì‚¼ì„±ì „ìì˜ ì‹¤ì ì´ í˜¸ì¡°ë¥¼ ë³´ì´ë©° ì£¼ê°€ê°€ ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "LGì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ì˜ í˜‘ë ¥ìœ¼ë¡œ ìƒˆë¡œìš´ ë°˜ë„ì²´ ê¸°ìˆ ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "í˜„ëŒ€ì°¨ì˜ ì‹ ì œí’ˆ ì¶œì‹œë¡œ ì‹œì¥ì—ì„œ ê¸ì •ì ì¸ ë°˜ì‘ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.",
        "ì¹´ì¹´ì˜¤ì˜ ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©ìë“¤ì—ê²Œ í˜¸í‰ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤."
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: {text}")
        try:
            stocks = analyzer.extract_stocks_from_text(text, analyzer.stock_list)
            print(f"  ì¶”ì¶œëœ ì¢…ëª©: {len(stocks)}ê°œ")
            for stock in stocks:
                print(f"    - {stock['name']} ({stock['code']}): ì‹ ë¢°ë„ {stock['confidence']}, ìœ„ì¹˜ {stock['position']}")
        except Exception as e:
            print(f"  âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

def test_explanation_generation():
    """ì„¤ëª…í˜• ë¶„ì„ê·¼ê±° ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n=== ì„¤ëª…í˜• ë¶„ì„ê·¼ê±° ìƒì„± í…ŒìŠ¤íŠ¸ ===")
    
    test_cases = [
        {
            "text": "ì‚¼ì„±ì „ìì˜ ì‹¤ì ì´ í˜¸ì¡°ë¥¼ ë³´ì´ë©° ì£¼ê°€ê°€ ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "company": "ì‚¼ì„±ì „ì",
            "industry": "ì „ìì—…",
            "sentiment": "positive"
        },
        {
            "text": "LGì „ìì˜ ë§¤ì¶œ ê°ì†Œë¡œ ì¸í•´ ì£¼ê°€ê°€ í•˜ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "company": "LGì „ì", 
            "industry": "ì „ìì—…",
            "sentiment": "negative"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}:")
        print(f"  í…ìŠ¤íŠ¸: {case['text']}")
        print(f"  íšŒì‚¬: {case['company']}, ì—…ì¢…: {case['industry']}")
        
        try:
            # ê¸°ë³¸ ì„¤ëª… ìƒì„±
            basic_explanation = generate_contextual_explanation(
                case['text'], case['company'], case['industry'], case['sentiment'], 'basic'
            )
            print(f"  ê¸°ë³¸ ì„¤ëª…: {basic_explanation}")
            
            # ë‹¤ì¤‘ ê´€ì  ì„¤ëª… ìƒì„±
            multi_explanations = generate_multi_perspective_explanation(
                case['text'], case['company'], case['industry'], case['sentiment']
            )
            print(f"  ë‹¤ì¤‘ ê´€ì :")
            for perspective, explanation in multi_explanations.items():
                print(f"    {perspective}: {explanation}")
        except Exception as e:
            print(f"  âŒ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")

def test_article_crawling():
    """ê¸°ì‚¬ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    print("\n=== ê¸°ì‚¬ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ìš© URL (ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ëŠ” URLì„ ì‚¬ìš©í•´ì•¼ í•¨)
    test_urls = [
        "https://example.com/test-article-1",
        "https://example.com/test-article-2"
    ]
    
    for i, url in enumerate(test_urls, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: {url}")
        try:
            content = fetch_article_content(url)
            if content:
                print(f"  í¬ë¡¤ë§ ì„±ê³µ: {len(content)}ì")
                print(f"  ë‚´ìš© ì¼ë¶€: {content[:100]}...")
            else:
                print("  í¬ë¡¤ë§ ì‹¤íŒ¨: ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        except Exception as e:
            print(f"  âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

def test_analysis_pipeline(analyzer):
    """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("\n=== ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ===")
    
    test_news = [
        {
            "title": "ì‚¼ì„±ì „ì ì‹¤ì  í˜¸ì¡°ë¡œ ì£¼ê°€ ìƒìŠ¹ì„¸",
            "content": "ì‚¼ì„±ì „ìê°€ ì˜ˆìƒë³´ë‹¤ ì¢‹ì€ ì‹¤ì ì„ ë°œí‘œí•˜ì—¬ ì£¼ê°€ê°€ ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°˜ë„ì²´ ë¶€ë¬¸ì˜ ë§¤ì¶œ ì¦ê°€ê°€ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
            "link": "https://example.com/samsung-news"
        },
        {
            "title": "LGì „ì ë§¤ì¶œ ê°ì†Œë¡œ ì£¼ê°€ í•˜ë½",
            "content": "LGì „ìì˜ ìµœê·¼ ì‹¤ì  ë°œí‘œì—ì„œ ë§¤ì¶œ ê°ì†Œê°€ í™•ì¸ë˜ì–´ ì£¼ê°€ê°€ í•˜ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²½ê¸° ì•…í™”ê°€ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ì§€ì ë©ë‹ˆë‹¤.",
            "link": "https://example.com/lg-news"
        }
    ]
    
    for i, news in enumerate(test_news, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ {i}: {news['title']}")
        try:
            processed, failed = analyzer.process_news_batch([news])
            print(f"  ì²˜ë¦¬ ê²°ê³¼: ì„±ê³µ {processed}ê°œ, ì‹¤íŒ¨ {failed}ê°œ")
        except Exception as e:
            print(f"  âŒ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ê°œì„ ëœ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    try:
        # 1. NewsAnalyzer í…ŒìŠ¤íŠ¸
        analyzer = test_news_analyzer()
        if not analyzer:
            print("NewsAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        # 2. ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸
        test_sentiment_analysis()
        
        # 3. ì¢…ëª© ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        test_stock_extraction(analyzer)
        
        # 4. ì„¤ëª…í˜• ë¶„ì„ê·¼ê±° ìƒì„± í…ŒìŠ¤íŠ¸
        test_explanation_generation()
        
        # 5. ê¸°ì‚¬ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
        test_article_crawling()
        
        # 6. ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        test_analysis_pipeline(analyzer)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 